{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3c0f0b",
   "metadata": {},
   "source": [
    "# Bronze para Silver\n",
    "\n",
    "## Arquitetura Medallion - Camada Silver\n",
    "\n",
    "Este script realiza a transformação dos dados da camada Bronze para a camada Silver.\n",
    "\n",
    "### Operações realizadas:\n",
    "- Limpeza e tratamento de valores nulos/inválidos\n",
    "- Normalização de colunas e padronização de nomes\n",
    "- Transformações e enriquecimento dos dados\n",
    "- Criação do modelo relacional e joins\n",
    "\n",
    "### Regras da camada Silver:\n",
    "- Dados limpos e estruturados\n",
    "- Chaves estrangeiras consistentes\n",
    "- Valores normalizados e padronizados\n",
    "- Pronta para análises relacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65658203",
   "metadata": {},
   "source": [
    "# Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c90b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be41228",
   "metadata": {},
   "source": [
    "# Configuração de Diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195c267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "BRONZE_DIR = os.path.join(BASE_DIR, 'bronze')\n",
    "SILVER_DIR = os.path.join(BASE_DIR, 'silver')\n",
    "\n",
    "if not os.path.exists(SILVER_DIR):\n",
    "    os.makedirs(SILVER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a4eaf",
   "metadata": {},
   "source": [
    "# Carregamento dos dados da camada Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad7802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas disponíveis na camada Bronze: ['olist_customers_dataset', 'olist_geolocation_dataset', 'olist_orders_dataset', 'olist_order_items_dataset', 'olist_order_payments_dataset', 'olist_order_reviews_dataset', 'olist_products_dataset', 'olist_sellers_dataset', 'product_category_name_translation']\n"
     ]
    }
   ],
   "source": [
    "bronze_db_path = os.path.join(BRONZE_DIR, 'bronze_layer.db')\n",
    "conn = sqlite3.connect(bronze_db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "print(f\"Tabelas disponíveis na camada Bronze: {tables}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf43909",
   "metadata": {},
   "source": [
    "# Carregar Tabelas Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6818fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregada tabela olist_customers_dataset: 99441 linhas, 8 colunas\n",
      "Carregada tabela olist_geolocation_dataset: 1000163 linhas, 8 colunas\n",
      "Carregada tabela olist_orders_dataset: 99441 linhas, 11 colunas\n",
      "Carregada tabela olist_order_items_dataset: 112650 linhas, 10 colunas\n",
      "Carregada tabela olist_order_payments_dataset: 103886 linhas, 8 colunas\n",
      "Carregada tabela olist_order_reviews_dataset: 99224 linhas, 10 colunas\n",
      "Carregada tabela olist_products_dataset: 32951 linhas, 12 colunas\n",
      "Carregada tabela olist_sellers_dataset: 3095 linhas, 7 colunas\n",
      "Carregada tabela product_category_name_translation: 71 linhas, 5 colunas\n"
     ]
    }
   ],
   "source": [
    "bronze_dfs = {}\n",
    "\n",
    "for table in tables:\n",
    "    pd_df = pd.read_sql_query(f\"SELECT * FROM {table}\", sqlite3.connect(bronze_db_path))\n",
    "    bronze_dfs[table] = pd_df\n",
    "    print(f\"Carregada tabela {table}: {len(pd_df)} linhas, {len(pd_df.columns)} colunas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd40b5",
   "metadata": {},
   "source": [
    "# Funções de tratamento para camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bab2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    \"\"\"Padroniza nomes de colunas para formato snake_case.\"\"\"\n",
    "    renamed_columns = {}\n",
    "    for old_col in df.columns:\n",
    "        new_col = old_col.lower().replace(' ', '_')\n",
    "        renamed_columns[old_col] = new_col\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "def remove_metadados_bronze(df):\n",
    "    \"\"\"Remove colunas de metadados da camada bronze.\"\"\"\n",
    "    meta_cols = ['_ingestion_timestamp', '_source_file', '_source_system']\n",
    "    meta_cols_to_drop = [col for col in meta_cols if col in df.columns]\n",
    "    if meta_cols_to_drop:\n",
    "        return df.drop(columns=meta_cols_to_drop)\n",
    "    return df\n",
    "\n",
    "def fix_datetime_columns(df, date_columns):\n",
    "    \"\"\"Converte colunas de data para formato datetime padrão.\"\"\"\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def normalize_text_columns(df, text_columns):\n",
    "    \"\"\"Normaliza colunas de texto: remove acentos, coloca em minúsculas.\"\"\"\n",
    "    result = df.copy()\n",
    "    for col in text_columns:\n",
    "        if col in result.columns:\n",
    "            result[col] = result[col].apply(\n",
    "                lambda x: unicodedata.normalize('NFKD', str(x) if pd.notna(x) else '')\n",
    "                .encode('ASCII', 'ignore')\n",
    "                .decode('ASCII')\n",
    "                .lower() if pd.notna(x) else x\n",
    "            )\n",
    "    return result\n",
    "\n",
    "def handle_missing_values(df, numeric_strategy='mean', categorical_strategy='unknown'):\n",
    "    \"\"\"Trata valores ausentes em colunas numéricas e categóricas.\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    numeric_cols = result.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = result.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    if numeric_strategy == 'mean':\n",
    "        for col in numeric_cols:\n",
    "            result[col] = result[col].fillna(result[col].mean())\n",
    "    elif numeric_strategy == 'median':\n",
    "        for col in numeric_cols:\n",
    "            result[col] = result[col].fillna(result[col].median())\n",
    "    elif numeric_strategy == 'zero':\n",
    "        result[numeric_cols] = result[numeric_cols].fillna(0)\n",
    "    \n",
    "    result[categorical_cols] = result[categorical_cols].fillna(categorical_strategy)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3ddb2",
   "metadata": {},
   "source": [
    "# Processamento dos Datasets para Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1606b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_dfs = {}\n",
    "\n",
    "silver_db_path = os.path.join(SILVER_DIR, 'silver_layer.db')\n",
    "silver_conn = sqlite3.connect(silver_db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb797d",
   "metadata": {},
   "source": [
    "# 1. Processamento de Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5968a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela customers: 99441 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_customers_dataset' in bronze_dfs:\n",
    "    customers_df = bronze_dfs['olist_customers_dataset']\n",
    "    customers_df = clean_column_names(customers_df)\n",
    "    customers_df = remove_metadados_bronze(customers_df)\n",
    "    customers_df = normalize_text_columns(customers_df, ['customer_city', 'customer_state'])\n",
    "    \n",
    "    silver_dfs['customers'] = customers_df\n",
    "    customers_df.to_sql('customers', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela customers: {len(customers_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e523c",
   "metadata": {},
   "source": [
    "# 2. Processamento de Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326638fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela orders: 99441 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_orders_dataset' in bronze_dfs:\n",
    "    orders_df = bronze_dfs['olist_orders_dataset']\n",
    "    orders_df = clean_column_names(orders_df)\n",
    "    orders_df = remove_metadados_bronze(orders_df)\n",
    "    \n",
    "    date_columns = [col for col in orders_df.columns if 'date' in col]\n",
    "    orders_df = fix_datetime_columns(orders_df, date_columns)\n",
    "    \n",
    "    silver_dfs['orders'] = orders_df\n",
    "    orders_df.to_sql('orders', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela orders: {len(orders_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830982bd",
   "metadata": {},
   "source": [
    "# 3. Processamento de Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73a4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela products: 32951 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_products_dataset' in bronze_dfs:\n",
    "    products_df = bronze_dfs['olist_products_dataset']\n",
    "    products_df = clean_column_names(products_df)\n",
    "    products_df = remove_metadados_bronze(products_df)\n",
    "    \n",
    "    if 'product_category_name_translation' in bronze_dfs:\n",
    "        translation_df = bronze_dfs['product_category_name_translation']\n",
    "        translation_df = clean_column_names(translation_df)\n",
    "        translation_df = remove_metadados_bronze(translation_df)\n",
    "        \n",
    "        translation_dict = dict(zip(\n",
    "            translation_df['product_category_name'],\n",
    "            translation_df['product_category_name_english']\n",
    "        ))\n",
    "        \n",
    "        products_df['product_category_name_english'] = products_df['product_category_name'].map(translation_dict)\n",
    "    \n",
    "    products_df = handle_missing_values(\n",
    "        products_df,\n",
    "        numeric_strategy='median',\n",
    "        categorical_strategy='unknown'\n",
    "    )\n",
    "    \n",
    "    silver_dfs['products'] = products_df\n",
    "    products_df.to_sql('products', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela products: {len(products_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fb6d9",
   "metadata": {},
   "source": [
    "# 4. Processamento de Order Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca46606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela order_items: 112650 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_order_items_dataset' in bronze_dfs:\n",
    "    order_items_df = bronze_dfs['olist_order_items_dataset']\n",
    "    order_items_df = clean_column_names(order_items_df)\n",
    "    order_items_df = remove_metadados_bronze(order_items_df)\n",
    "    \n",
    "    date_columns = [col for col in order_items_df.columns if 'date' in col]\n",
    "    order_items_df = fix_datetime_columns(order_items_df, date_columns)\n",
    "    \n",
    "    silver_dfs['order_items'] = order_items_df\n",
    "    order_items_df.to_sql('order_items', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela order_items: {len(order_items_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32198250",
   "metadata": {},
   "source": [
    "# 5. Processamento de Order Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c358ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela order_payments: 103886 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_order_payments_dataset' in bronze_dfs:\n",
    "    payments_df = bronze_dfs['olist_order_payments_dataset']\n",
    "    payments_df = clean_column_names(payments_df)\n",
    "    payments_df = remove_metadados_bronze(payments_df)\n",
    "    \n",
    "    silver_dfs['order_payments'] = payments_df\n",
    "    payments_df.to_sql('order_payments', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela order_payments: {len(payments_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a5068",
   "metadata": {},
   "source": [
    "# 6. Processamento de Order Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d15232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela order_reviews: 99224 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_order_reviews_dataset' in bronze_dfs:\n",
    "    reviews_df = bronze_dfs['olist_order_reviews_dataset']\n",
    "    reviews_df = clean_column_names(reviews_df)\n",
    "    reviews_df = remove_metadados_bronze(reviews_df)\n",
    "    \n",
    "    date_columns = [col for col in reviews_df.columns if 'date' in col]\n",
    "    reviews_df = fix_datetime_columns(reviews_df, date_columns)\n",
    "    \n",
    "    if 'review_comment_message' in reviews_df.columns:\n",
    "        reviews_df = normalize_text_columns(reviews_df, ['review_comment_message'])\n",
    "    \n",
    "    silver_dfs['order_reviews'] = reviews_df\n",
    "    reviews_df.to_sql('order_reviews', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela order_reviews: {len(reviews_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f72b2",
   "metadata": {},
   "source": [
    "# 7. Processamento de Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5911e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela sellers: 3095 linhas\n"
     ]
    }
   ],
   "source": [
    "if 'olist_sellers_dataset' in bronze_dfs:\n",
    "    sellers_df = bronze_dfs['olist_sellers_dataset']\n",
    "    sellers_df = clean_column_names(sellers_df)\n",
    "    sellers_df = remove_metadados_bronze(sellers_df)\n",
    "    sellers_df = normalize_text_columns(sellers_df, ['seller_city', 'seller_state'])\n",
    "    \n",
    "    silver_dfs['sellers'] = sellers_df\n",
    "    sellers_df.to_sql('sellers', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela sellers: {len(sellers_df)} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744afdeb",
   "metadata": {},
   "source": [
    "# 8. Processamento de Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f60b7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processada tabela geolocation: 19015 linhas (agrupada por CEP)\n",
      "\n",
      "Processamento para camada Silver concluído!\n",
      "Total de tabelas processadas: 8\n"
     ]
    }
   ],
   "source": [
    "if 'olist_geolocation_dataset' in bronze_dfs:\n",
    "    geo_df = bronze_dfs['olist_geolocation_dataset']\n",
    "    geo_df = clean_column_names(geo_df)\n",
    "    geo_df = remove_metadados_bronze(geo_df)\n",
    "    geo_df = normalize_text_columns(geo_df, ['geolocation_city', 'geolocation_state'])\n",
    "    \n",
    "    geo_grouped = geo_df.groupby('geolocation_zip_code_prefix').agg({\n",
    "        'geolocation_lat': 'mean',\n",
    "        'geolocation_lng': 'mean',\n",
    "        'geolocation_city': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
    "        'geolocation_state': lambda x: x.mode()[0] if not x.mode().empty else None\n",
    "    }).reset_index()\n",
    "    \n",
    "    silver_dfs['geolocation'] = geo_grouped\n",
    "    geo_grouped.to_sql('geolocation', silver_conn, if_exists='replace', index=False)\n",
    "    print(f\"Processada tabela geolocation: {len(geo_grouped)} linhas (agrupada por CEP)\")\n",
    "\n",
    "silver_conn.close()\n",
    "\n",
    "print(\"\\nProcessamento para camada Silver concluído!\")\n",
    "print(f\"Total de tabelas processadas: {len(silver_dfs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ab0cc",
   "metadata": {},
   "source": [
    "# Salvar metadados da camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166d0115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "silver_metadata = {\n",
    "    'tables': list(silver_dfs.keys()),\n",
    "    'row_counts': {table: len(df) for table, df in silver_dfs.items()},\n",
    "    'processing_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(SILVER_DIR, 'silver_metadata.json'), 'w') as f:\n",
    "    import json\n",
    "    json.dump(silver_metadata, f, indent=2)\n",
    "\n",
    "print(\"Metadados salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
